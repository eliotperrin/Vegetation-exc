{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22406924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_to_percentage(value):\n",
    "    bb_dict = {\n",
    "        'r': 0,\n",
    "        '+': 0.3,\n",
    "        '1': 3,\n",
    "        '2a': 9,\n",
    "        '2b': 19,\n",
    "        '3': 32,\n",
    "        '4': 57,\n",
    "        '5': 90\n",
    "    }\n",
    "    if isinstance(value, str) and value in bb_dict:\n",
    "        return bb_dict[value]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cac42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bb_to_column(df, col_index):\n",
    "    col = df.iloc[:, col_index]\n",
    "    transformed_col = []\n",
    "    for value in col:\n",
    "        transformed_value = bb_to_percentage(value)\n",
    "        transformed_col.append(transformed_value)\n",
    "    result_array = np.array(transformed_col)\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8678849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landolt_values(species, landolt_data):\n",
    "    landolt_values = landolt_data[landolt_data['Espece'].isin(species)]\n",
    "    return landolt_values[['Espece', 'T', 'L', 'K', 'R', 'N', 'F']]\n",
    "\n",
    "def calculate_weighted_landolt(species, coverages, landolt_data):\n",
    "    landolt_values = get_landolt_values(species, landolt_data)\n",
    "    \n",
    "    # Associer les recouvrements aux espèces correspondantes\n",
    "    species_coverage = pd.DataFrame({'Espece': species, 'Coverage': coverages})\n",
    "    combined_data = pd.merge(species_coverage, landolt_values, on='Espece', how='left')\n",
    "\n",
    "    # Convertir les colonnes en types numériques\n",
    "    for col in ['T', 'L', 'K', 'R', 'N', 'F']:\n",
    "        combined_data[col] = pd.to_numeric(combined_data[col], errors='coerce')\n",
    "    \n",
    "    # Calculer les moyennes pondérées\n",
    "    weighted_landolt = {}\n",
    "    weighted_error = {}\n",
    "    total_coverage = combined_data['Coverage'].sum()\n",
    "    if total_coverage == 0:\n",
    "        return {col: (np.nan, np.nan) for col in ['T', 'L', 'K', 'R', 'N', 'F']}\n",
    "    \n",
    "    for col in ['T', 'L', 'K', 'R', 'N', 'F']:\n",
    "        combined_data[col + '_weighted'] = combined_data[col] * combined_data['Coverage']\n",
    "        mean = combined_data[col + '_weighted'].sum() / total_coverage\n",
    "        weighted_landolt[col] = mean\n",
    "        \n",
    "        # Calcul de l'erreur standard pondérée\n",
    "        variance = combined_data.apply(lambda row: (row[col] - mean) ** 2 * row['Coverage'], axis=1).sum() / total_coverage\n",
    "        standard_error = np.sqrt(variance) / np.sqrt(total_coverage)\n",
    "        weighted_error[col] = standard_error\n",
    "    \n",
    "    # Retourner les moyennes et les erreurs standard pondérées\n",
    "    return {col: (weighted_landolt[col], weighted_error[col]) for col in ['T', 'L', 'K', 'R', 'N', 'F']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05cee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recouvrement transformé: [ 9.   9.   0.3  9.  32.  32.   9.   3.   0.   0.   0.   0.   0.3 32.\n",
      "  3.   0.   0.3  nan  9.   0.3  0.3  0.3 32.   3.   0.  57.  19.   0.\n",
      "  0.3  0.3  0.   nan  nan  0.3 57.   0.3  3.   0.3  0.3  0.3  0.3  3.\n",
      "  0.3  0.3  0.3  9.   nan  0.3  0.3  0.3  0.3  0.3  0.   0.3  0.  57.\n",
      "  0.3  0.3  0.   0.   0.3  0.   0.3  3.  19.   3.   0.3  9.   9.  19.\n",
      " 19.   0.3  0.3  0.3  0.3  9.   9.   3.   3.   3.   3.   3.   0.3  0.3\n",
      "  0.3  0.3  0.3 57.   3.   3.   3.   0.3  0.3  0.3  0.3  0.3  0.3  0.3\n",
      "  0.   0. ]\n",
      "Espèces: ['Rubus fruticosus aggr.' 'Salix aurita' 'Salix purpurea'\n",
      " 'Equisetum palustre' 'Rubus fruticosus aggr.' 'Phragmites australis'\n",
      " 'Cirsium arvense' 'Lysimachia vulgaris' 'Filipendula ulmaria'\n",
      " 'Thalictrum flavum' 'Symphytum officinale' 'Cornus sanguinea'\n",
      " 'Rorippa palustris' 'Solidago gigantea' 'Carex hirta' 'Quercus sp.'\n",
      " 'Salix purpurea' '(Alnus glutinosa)' 'Lysimachia vulgaris'\n",
      " 'Symphytum officinale' 'Galium palustre' 'Hydrocotyle vulgaris'\n",
      " 'Cladium mariscus' 'Phragmites australis' 'Mentha aquatica' 'bryophytes'\n",
      " 'Carex elata' 'Carex panicea' 'Cirsium palustre' 'Lathyrus palustris'\n",
      " 'Peucedanum palustre' '(Carex lasiocarpa)' '(Nymphaea alba)'\n",
      " 'Frangula alnus' 'Schoenus nigricans' 'Lysimachia vulgaris'\n",
      " 'Cladium mariscus' 'Hydrocotyle vulgaris' 'Galium palustre'\n",
      " 'Phragmites australis' 'Thalictrum flavum' 'Carex hostiana'\n",
      " 'Veronica beccabunga' 'Gentiana pneumonanthe' 'Peucedanum palustre'\n",
      " 'Molinia caerulea' '(Epipactis palustris)' 'Alnus incana' 'Alnus incana'\n",
      " 'Sanguisorba officinalis' 'Hydrocotyle vulgaris' 'Frangula alnus'\n",
      " 'Gentiana pneumonanthe' 'Salix myrsinifolia' 'Schoenus nigricans'\n",
      " 'Peucedanum palustre' 'Polygala amarella' 'Salix cinerea'\n",
      " 'Linum catharticum' 'Galium palustre' 'Epipactis palustris'\n",
      " 'Vicia cracca' 'Cladium mariscus' 'Molinia caerulea' 'Carex panicea'\n",
      " 'Carex hostiana' 'Corylus avellana' 'Betula pendula' 'Quercus robur'\n",
      " 'Rhamnus cathartica' 'Fraxinus excelsior' 'Euonymus europaeus'\n",
      " 'Crataegus monogyna' 'Hedera helix' 'Corylus avellana'\n",
      " 'Ligustrum vulgare' 'Viburnum lantana' 'Prunus spinosa'\n",
      " 'Cornus sanguinea' 'Rhamnus cathartica' 'Crataegus monogyna'\n",
      " 'Populus tremula' 'Hedera helix' 'Tamus communis' 'Berberis vulgaris'\n",
      " 'Lonicera xylosteum' 'Carex flacca' 'Rubus caesius' 'Ligustrum vulgare'\n",
      " 'Brachypodium sylvaticum' 'Hedera helix' 'Euonymus europaeus'\n",
      " 'Fraxinus excelsior' 'Tamus communis' 'Viburnum lantana'\n",
      " 'Cornus sanguinea' 'Corylus avellana' 'Crataegus monogyna' 'Rosa sp.'\n",
      " 'Lonicera xylosteum']\n",
      "Sites: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_path = 'Végétation excursions.xlsx'  # Remplacez par le chemin de votre fichier\n",
    "    flora_data_path = 'FloraIndicativa_clean_R.xlsx'\n",
    "    flora_data_sheet = 'vasc'\n",
    "    \n",
    "    # Lire le fichier principal\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Appliquer la transformation de recouvrement sur la colonne 3\n",
    "    coverage = apply_bb_to_column(df, 3)\n",
    "    print(\"Recouvrement transformé:\", coverage)\n",
    "    \n",
    "    # Extraire les espèces de la colonne 2\n",
    "    species = df.iloc[:, 2].values\n",
    "    print(\"Espèces:\", species)\n",
    "    \n",
    "    # Extraire les sites de la colonne 0\n",
    "    sites = df.iloc[:, 0].values\n",
    "    print(\"Sites:\", sites)\n",
    "    \n",
    "    # Lire les données de FloraIndicativa\n",
    "    landolt_data = pd.read_excel(flora_data_path, sheet_name=flora_data_sheet)\n",
    "    \n",
    "    # Calculer les indices de Landolt pondérés pour chaque site\n",
    "    site_landolt_indices = {}\n",
    "    unique_sites = np.unique(sites)\n",
    "    \n",
    "    for site in unique_sites:\n",
    "        site_mask = sites == site\n",
    "        site_species = species[site_mask]\n",
    "        site_coverage = coverage[site_mask]\n",
    "        site_landolt_indices[site] = calculate_weighted_landolt(site_species, site_coverage, landolt_data)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
